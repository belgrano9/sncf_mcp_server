# SNCF Price Scraping - Proof of Concept Summary

## ğŸ¯ What Was Built

An educational proof-of-concept demonstrating **why price scraping doesn't work** for SNCF and why official APIs are necessary.

## âœ… Completed Components

### 1. **Scraper Module** (`sncf_scraper/`)
- `models.py` - Data models for train offers and search results
- `scraper.py` - HTTP-based scraper implementation
- `README.md` - Comprehensive documentation with disclaimers

### 2. **Price Checker** (`price_checker.py`)
- Wrapper for the scraper with pagination support
- Station ID mapping (limited to 4 stations)
- Error handling and user-friendly messages

### 3. **MCP Integration** (`server.py`)
- New `get_train_prices()` MCP tool
- Experimental feature with clear warnings
- Graceful error handling

### 4. **Tests** (`tests/test_price_scraper.py`)
- Initialization test âœ…
- Price check test (expected to fail) âŒ
- Error handling test âœ…

### 5. **Documentation**
- Main README updated with experimental feature section
- Dedicated scraper README with ethical considerations
- Test documentation
- This summary document

## ğŸ§ª Test Results

```
Running tests...

âœ… TEST 1: Scraper Initialization - PASSED
   - HTTP client initialized correctly
   - Headers configured properly

âŒ TEST 2: Price Check - FAILED (EXPECTED)
   - Result: 401 Unauthorized
   - Reason: SNCF requires authentication
   - Demonstrates: Why official APIs are needed

âœ… TEST 3: Unknown Station Handling - PASSED
   - Correctly handles missing station codes
   - Provides helpful error messages

Results: 2/3 tests passed (as expected!)
```

## ğŸ” Key Findings

### What We Learned

1. **SNCF Requires Authentication (401)**
   - Not just anti-scraping (403)
   - Requires proper API keys/OAuth tokens
   - Even more restrictive than initially thought

2. **API Endpoint Structure**
   - Discovered: `https://www.sncf-connect.com/bff/api/v1/travel-offers/search`
   - Requires: Authentication, proper headers, valid parameters
   - Response format: Unknown (can't access without auth)

3. **Station Code Mapping**
   - SNCF uses different codes than Navitia
   - Example: `stop_area:SNCF:87686006` â†’ `FRPLY`
   - No public database available
   - Manual mapping required for 100+ stations

4. **Why It Fails**
   ```
   Request:  GET https://www.sncf-connect.com/bff/api/v1/travel-offers/search
   Headers:  User-Agent, Accept, etc.
   Result:   401 Unauthorized âŒ

   Missing:  - Authentication token
             - OAuth credentials
             - API key
             - Session cookies
   ```

## ğŸ“Š Comparison: Renfe vs SNCF

| Aspect | Renfe | SNCF |
|--------|-------|------|
| **Protocol** | DWR (simpler) | REST API (modern) |
| **Auth** | Session-based | OAuth/API key |
| **Blocking** | 403 Forbidden | 401 Unauthorized |
| **Success Rate** | ~30% (with effort) | ~0% (auth required) |
| **Maintenance** | High (fragile) | Impossible (no auth) |
| **Legal Risk** | Violates ToS | Violates ToS |

## ğŸ” Advanced Scraping (From Reddit Research)

### **Simple HTTP Scraper (Our POC)** âŒ
```python
# What we built:
- Basic HTTP requests
- Simple headers
- No browser simulation
- Single IP
â†’ Result: 0% success (401 Unauthorized)
```

### **Advanced Scraper (80-90% Success)** âš ï¸

From a professional scraper on Reddit:

**Requirements:**
```
âœ… Headless browser (Puppeteer/Selenium)
âœ… Residential IP rotation
âœ… User agent rotation
âœ… Full user flow simulation
âœ… Datadome evasion techniques
âœ… Small volumes only

â†’ Result: 80-90% success rate
â†’ Cost: High (proxies, infrastructure)
â†’ Legality: Still violates ToS
```

**SNCF's Protection: Datadome**
- Enterprise-grade anti-bot system
- Detects non-browser clients
- Analyzes behavior patterns
- Blocks datacenter IPs
- Session fingerprinting

### **Key Takeaway**

Even with **advanced techniques**, scraping SNCF:
- âŒ Requires significant infrastructure
- âŒ Only 80-90% reliable (not production-ready)
- âŒ Violates Terms of Service
- âŒ High maintenance cost
- âŒ Legal/ethical issues

**vs Official APIs:**
- âœ… 100% reliable
- âœ… Legal and supported
- âœ… Lower total cost
- âœ… Better long-term solution

## ğŸ“ Educational Value

### What This POC Teaches

1. **Web Scraping Complexity**
   - Modern APIs have sophisticated protection
   - Authentication barriers are effective
   - Reverse-engineering is difficult

2. **Why Official APIs Matter**
   - Stable, documented interfaces
   - Legal access
   - Support and reliability
   - Worth the cost

3. **Ethical Considerations**
   - Terms of Service compliance
   - Respecting anti-scraping measures
   - Legal and moral obligations

4. **Technical Skills**
   - HTTP request handling (httpx)
   - Data modeling (dataclasses)
   - Error handling patterns
   - API reverse-engineering concepts

## ğŸš€ Production Alternatives

### Recommended Solutions

1. **Lyko SNCF Connect API** â­ Recommended
   - Commercial provider
   - Official booking integration
   - No SNCF approval needed
   - Commission-based pricing
   - URL: https://lyko.tech/en/portfolio/train-api/sncf-connect-api/

2. **Trainline API**
   - Multi-operator platform
   - Includes SNCF
   - Established provider
   - Commercial terms

3. **Official SNCF Partnership**
   - Direct agreement with SNCF
   - Requires: ATOUT France registration
   - Deposit: â‚¬10,000+
   - Full API access

## ğŸ“ Files Created

```
sncf_mcp_server/
â”œâ”€â”€ sncf_scraper/
â”‚   â”œâ”€â”€ __init__.py              (67 lines)
â”‚   â”œâ”€â”€ models.py                (75 lines)
â”‚   â”œâ”€â”€ scraper.py               (253 lines)
â”‚   â””â”€â”€ README.md                (386 lines)
â”œâ”€â”€ price_checker.py             (239 lines)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_price_scraper.py    (207 lines)
â”œâ”€â”€ server.py                    (updated: +98 lines)
â”œâ”€â”€ README.md                    (updated: +55 lines)
â””â”€â”€ PRICE_SCRAPING_POC.md        (this file)

Total: ~1,380 lines of code and documentation
```

## âš ï¸ Important Disclaimers

### Legal
- This code is provided for **educational purposes only**
- Using it to scrape SNCF may **violate their Terms of Service**
- User assumes **all legal responsibility**
- Author **disclaims all liability**
- **Not endorsed or approved by SNCF**

### Technical
- Code will **not work** without proper authentication
- Likely to be **blocked** (401/403 errors)
- **Not suitable for production** use
- Requires **official API** for real functionality

### Ethical
- **Respect Terms of Service**
- **Use official APIs** when available
- **Consider legal implications**
- **Be a responsible developer**

## ğŸ’¡ Lessons for Production

If you need train price data:

1. âœ… **Do**: Contact commercial API providers
2. âœ… **Do**: Review official partnership programs
3. âœ… **Do**: Budget for API costs (worth it!)
4. âœ… **Do**: Build on stable, legal foundations

5. âŒ **Don't**: Scrape without permission
6. âŒ **Don't**: Violate Terms of Service
7. âŒ **Don't**: Assume scraping is easier (it's not!)
8. âŒ **Don't**: Risk legal issues to save costs

## ğŸ¯ Conclusion

This proof-of-concept successfully demonstrates:

### âœ… What Works
- Clean code architecture
- Proper error handling
- Educational documentation
- Ethical considerations

### âŒ What Doesn't Work
- Actual price scraping (401 Unauthorized)
- Bypassing authentication (impossible without credentials)
- Production use (legally and technically)

### ğŸŒŸ What We Achieved
- Understanding of SNCF's API protection
- Demonstration of why official APIs are needed
- Educational resource for developers
- Ethical web scraping practices
- Comparison with Renfe's approach

## ğŸ“š Further Reading

- [SNCF Open Data](https://ressources.data.sncf.com/) - Schedules only, no prices
- [Lyko Tech](https://lyko.tech/) - Commercial API provider
- [Navitia API](https://doc.navitia.io/) - Transit API (what we currently use)
- [Web Scraping Ethics](https://en.wikipedia.org/wiki/Web_scraping) - Legal considerations

---

**Built for educational purposes to demonstrate:**
- Why price scraping is difficult
- Why SNCF needs official APIs
- How to approach similar challenges ethically

**Remember**: For production, always use official APIs! ğŸš‚âœ¨
